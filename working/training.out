nohup: ignoring input
Using SCRIPTS_ROOTDIR: /usr/local/mosesdecoder/scripts
Using single-thread GIZA
(1) preparing corpus @ Thu Apr 14 13:34:17 IST 2016
Executing: mkdir -p /users/case4/smitha47/SMT-Project/working/train/corpus
(1.0) selecting factors @ Thu Apr 14 13:34:17 IST 2016
(1.1) running mkcls  @ Thu Apr 14 13:34:17 IST 2016
/usr/local/mosesdecoder/tools/mkcls -c50 -n2 -p/users/case4/smitha47/SMT-Project/corpus/train-data-clean.fr -V/users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb.classes opt
Executing: /usr/local/mosesdecoder/tools/mkcls -c50 -n2 -p/users/case4/smitha47/SMT-Project/corpus/train-data-clean.fr -V/users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb.classes opt

***** 2 runs. (algorithm:TA)*****
;KategProblem:cats: 50   words: 2708

start-costs: MEAN: 148038 (147287-148788)  SIGMA:750.341   
  end-costs: MEAN: 127008 (127008-127008)  SIGMA:0.199888   
   start-pp: MEAN: 245.08 (233.602-256.558)  SIGMA:11.4778   
     end-pp: MEAN: 65.8227 (65.8219-65.8236)  SIGMA:0.000821805   
 iterations: MEAN: 65120 (64557-65683)  SIGMA:563   
       time: MEAN: 1.0255 (1.007-1.044)  SIGMA:0.0185   
(1.1) running mkcls  @ Thu Apr 14 13:34:19 IST 2016
/usr/local/mosesdecoder/tools/mkcls -c50 -n2 -p/users/case4/smitha47/SMT-Project/corpus/train-data-clean.en -V/users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb.classes opt
Executing: /usr/local/mosesdecoder/tools/mkcls -c50 -n2 -p/users/case4/smitha47/SMT-Project/corpus/train-data-clean.en -V/users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb.classes opt

***** 2 runs. (algorithm:TA)*****
;KategProblem:cats: 50   words: 2586

start-costs: MEAN: 154191 (153826-154556)  SIGMA:364.864   
  end-costs: MEAN: 134580 (134326-134834)  SIGMA:253.585   
   start-pp: MEAN: 214.898 (210.163-219.633)  SIGMA:4.7352   
     end-pp: MEAN: 65.7271 (64.7204-66.7337)  SIGMA:1.00665   
 iterations: MEAN: 63753.5 (63097-64410)  SIGMA:656.5   
       time: MEAN: 1.0755 (0.954-1.197)  SIGMA:0.1215   
(1.2) creating vcb file /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb @ Thu Apr 14 13:34:21 IST 2016
(1.2) creating vcb file /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb @ Thu Apr 14 13:34:22 IST 2016
(1.3) numberizing corpus /users/case4/smitha47/SMT-Project/working/train/corpus/fr-en-int-train.snt @ Thu Apr 14 13:34:22 IST 2016
(1.3) numberizing corpus /users/case4/smitha47/SMT-Project/working/train/corpus/en-fr-int-train.snt @ Thu Apr 14 13:34:22 IST 2016
(2) running giza @ Thu Apr 14 13:34:22 IST 2016
(2.1a) running snt2cooc fr-en @ Thu Apr 14 13:34:22 IST 2016

Executing: mkdir -p /users/case4/smitha47/SMT-Project/working/train/giza.fr-en
Executing: /usr/local/mosesdecoder/tools/snt2cooc.out /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb /users/case4/smitha47/SMT-Project/working/train/corpus/fr-en-int-train.snt > /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en.cooc
/usr/local/mosesdecoder/tools/snt2cooc.out /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb /users/case4/smitha47/SMT-Project/working/train/corpus/fr-en-int-train.snt > /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en.cooc
END.
(2.1b) running giza fr-en @ Thu Apr 14 13:34:22 IST 2016
/usr/local/mosesdecoder/tools/GIZA++  -CoocurrenceFile /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en.cooc -c /users/case4/smitha47/SMT-Project/working/train/corpus/fr-en-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en -onlyaldumps 1 -p0 0.999 -s /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb -t /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb
Executing: /usr/local/mosesdecoder/tools/GIZA++  -CoocurrenceFile /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en.cooc -c /users/case4/smitha47/SMT-Project/working/train/corpus/fr-en-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en -onlyaldumps 1 -p0 0.999 -s /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb -t /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb
/usr/local/mosesdecoder/tools/GIZA++  -CoocurrenceFile /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en.cooc -c /users/case4/smitha47/SMT-Project/working/train/corpus/fr-en-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en -onlyaldumps 1 -p0 0.999 -s /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb -t /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb
Parameter 'coocurrencefile' changed from '' to '/users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en.cooc'
Parameter 'c' changed from '' to '/users/case4/smitha47/SMT-Project/working/train/corpus/fr-en-int-train.snt'
Parameter 'm3' changed from '5' to '3'
Parameter 'm4' changed from '5' to '3'
Parameter 'model1dumpfrequency' changed from '0' to '1'
Parameter 'model4smoothfactor' changed from '0.2' to '0.4'
Parameter 'nodumps' changed from '0' to '1'
Parameter 'nsmooth' changed from '64' to '4'
Parameter 'o' changed from '116-04-14.133422.smitha47' to '/users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en'
Parameter 'onlyaldumps' changed from '0' to '1'
Parameter 'p0' changed from '-1' to '0.999'
Parameter 's' changed from '' to '/users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb'
Parameter 't' changed from '' to '/users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb'
general parameters:
-------------------
ml = 101  (maximum sentence length)

No. of iterations:
-------------------
hmmiterations = 5  (mh)
model1iterations = 5  (number of iterations for Model 1)
model2iterations = 0  (number of iterations for Model 2)
model3iterations = 3  (number of iterations for Model 3)
model4iterations = 3  (number of iterations for Model 4)
model5iterations = 0  (number of iterations for Model 5)
model6iterations = 0  (number of iterations for Model 6)

parameter for various heuristics in GIZA++ for efficient training:
------------------------------------------------------------------
countincreasecutoff = 1e-06  (Counts increment cutoff threshold)
countincreasecutoffal = 1e-05  (Counts increment cutoff threshold for alignments in training of fertility models)
mincountincrease = 1e-07  (minimal count increase)
peggedcutoff = 0.03  (relative cutoff probability for alignment-centers in pegging)
probcutoff = 1e-07  (Probability cutoff threshold for lexicon probabilities)
probsmooth = 1e-07  (probability smoothing (floor) value )

parameters for describing the type and amount of output:
-----------------------------------------------------------
compactalignmentformat = 0  (0: detailled alignment format, 1: compact alignment format )
hmmdumpfrequency = 0  (dump frequency of HMM)
l = 116-04-14.133422.smitha47.log  (log file name)
log = 0  (0: no logfile; 1: logfile)
model1dumpfrequency = 1  (dump frequency of Model 1)
model2dumpfrequency = 0  (dump frequency of Model 2)
model345dumpfrequency = 0  (dump frequency of Model 3/4/5)
nbestalignments = 0  (for printing the n best alignments)
nodumps = 1  (1: do not write any files)
o = /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en  (output file prefix)
onlyaldumps = 1  (1: do not write any files)
outputpath =   (output path)
transferdumpfrequency = 0  (output: dump of transfer from Model 2 to 3)
verbose = 0  (0: not verbose; 1: verbose)
verbosesentence = -10  (number of sentence for which a lot of information should be printed (negative: no output))

parameters describing input files:
----------------------------------
c = /users/case4/smitha47/SMT-Project/working/train/corpus/fr-en-int-train.snt  (training corpus file name)
d =   (dictionary file name)
s = /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb  (source vocabulary file name)
t = /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb  (target vocabulary file name)
tc =   (test corpus file name)

smoothing parameters:
---------------------
emalsmooth = 0.2  (f-b-trn: smoothing factor for HMM alignment model (can be ignored by -emSmoothHMM))
model23smoothfactor = 0  (smoothing parameter for IBM-2/3 (interpolation with constant))
model4smoothfactor = 0.4  (smooting parameter for alignment probabilities in Model 4)
model5smoothfactor = 0.1  (smooting parameter for distortion probabilities in Model 5 (linear interpolation with constant))
nsmooth = 4  (smoothing for fertility parameters (good value: 64): weight for wordlength-dependent fertility parameters)
nsmoothgeneral = 0  (smoothing for fertility parameters (default: 0): weight for word-independent fertility parameters)

parameters modifying the models:
--------------------------------
compactadtable = 1  (1: only 3-dimensional alignment table for IBM-2 and IBM-3)
deficientdistortionforemptyword = 0  (0: IBM-3/IBM-4 as described in (Brown et al. 1993); 1: distortion model of empty word is deficient; 2: distoriton model of empty word is deficient (differently); setting this parameter also helps to avoid that during IBM-3 and IBM-4 training too many words are aligned with the empty word)
depm4 = 76  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
depm5 = 68  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
emalignmentdependencies = 2  (lextrain: dependencies in the HMM alignment model.  &1: sentence length; &2: previous class; &4: previous position;  &8: French position; &16: French class)
emprobforempty = 0.4  (f-b-trn: probability for empty word)

parameters modifying the EM-algorithm:
--------------------------------------
m5p0 = -1  (fixed value for parameter p_0 in IBM-5 (if negative then it is determined in training))
manlexfactor1 = 0  ()
manlexfactor2 = 0  ()
manlexmaxmultiplicity = 20  ()
maxfertility = 10  (maximal fertility for fertility models)
p0 = 0.999  (fixed value for parameter p_0 in IBM-3/4 (if negative then it is determined in training))
pegging = 0  (0: no pegging; 1: do pegging)

general parameters:
-------------------
ml = 101  (maximum sentence length)

No. of iterations:
-------------------
hmmiterations = 5  (mh)
model1iterations = 5  (number of iterations for Model 1)
model2iterations = 0  (number of iterations for Model 2)
model3iterations = 3  (number of iterations for Model 3)
model4iterations = 3  (number of iterations for Model 4)
model5iterations = 0  (number of iterations for Model 5)
model6iterations = 0  (number of iterations for Model 6)

parameter for various heuristics in GIZA++ for efficient training:
------------------------------------------------------------------
countincreasecutoff = 1e-06  (Counts increment cutoff threshold)
countincreasecutoffal = 1e-05  (Counts increment cutoff threshold for alignments in training of fertility models)
mincountincrease = 1e-07  (minimal count increase)
peggedcutoff = 0.03  (relative cutoff probability for alignment-centers in pegging)
probcutoff = 1e-07  (Probability cutoff threshold for lexicon probabilities)
probsmooth = 1e-07  (probability smoothing (floor) value )

parameters for describing the type and amount of output:
-----------------------------------------------------------
compactalignmentformat = 0  (0: detailled alignment format, 1: compact alignment format )
hmmdumpfrequency = 0  (dump frequency of HMM)
l = 116-04-14.133422.smitha47.log  (log file name)
log = 0  (0: no logfile; 1: logfile)
model1dumpfrequency = 1  (dump frequency of Model 1)
model2dumpfrequency = 0  (dump frequency of Model 2)
model345dumpfrequency = 0  (dump frequency of Model 3/4/5)
nbestalignments = 0  (for printing the n best alignments)
nodumps = 1  (1: do not write any files)
o = /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en  (output file prefix)
onlyaldumps = 1  (1: do not write any files)
outputpath =   (output path)
transferdumpfrequency = 0  (output: dump of transfer from Model 2 to 3)
verbose = 0  (0: not verbose; 1: verbose)
verbosesentence = -10  (number of sentence for which a lot of information should be printed (negative: no output))

parameters describing input files:
----------------------------------
c = /users/case4/smitha47/SMT-Project/working/train/corpus/fr-en-int-train.snt  (training corpus file name)
d =   (dictionary file name)
s = /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb  (source vocabulary file name)
t = /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb  (target vocabulary file name)
tc =   (test corpus file name)

smoothing parameters:
---------------------
emalsmooth = 0.2  (f-b-trn: smoothing factor for HMM alignment model (can be ignored by -emSmoothHMM))
model23smoothfactor = 0  (smoothing parameter for IBM-2/3 (interpolation with constant))
model4smoothfactor = 0.4  (smooting parameter for alignment probabilities in Model 4)
model5smoothfactor = 0.1  (smooting parameter for distortion probabilities in Model 5 (linear interpolation with constant))
nsmooth = 4  (smoothing for fertility parameters (good value: 64): weight for wordlength-dependent fertility parameters)
nsmoothgeneral = 0  (smoothing for fertility parameters (default: 0): weight for word-independent fertility parameters)

parameters modifying the models:
--------------------------------
compactadtable = 1  (1: only 3-dimensional alignment table for IBM-2 and IBM-3)
deficientdistortionforemptyword = 0  (0: IBM-3/IBM-4 as described in (Brown et al. 1993); 1: distortion model of empty word is deficient; 2: distoriton model of empty word is deficient (differently); setting this parameter also helps to avoid that during IBM-3 and IBM-4 training too many words are aligned with the empty word)
depm4 = 76  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
depm5 = 68  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
emalignmentdependencies = 2  (lextrain: dependencies in the HMM alignment model.  &1: sentence length; &2: previous class; &4: previous position;  &8: French position; &16: French class)
emprobforempty = 0.4  (f-b-trn: probability for empty word)

parameters modifying the EM-algorithm:
--------------------------------------
m5p0 = -1  (fixed value for parameter p_0 in IBM-5 (if negative then it is determined in training))
manlexfactor1 = 0  ()
manlexfactor2 = 0  ()
manlexmaxmultiplicity = 20  ()
maxfertility = 10  (maximal fertility for fertility models)
p0 = 0.999  (fixed value for parameter p_0 in IBM-3/4 (if negative then it is determined in training))
pegging = 0  (0: no pegging; 1: do pegging)

reading vocabulary files 
Reading vocabulary file from:/users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb
Reading vocabulary file from:/users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb
Source vocabulary list has 2587 unique tokens 
Target vocabulary list has 2709 unique tokens 
Calculating vocabulary frequencies from corpus /users/case4/smitha47/SMT-Project/working/train/corpus/fr-en-int-train.snt
Reading more sentence pairs into memory ... 
Corpus fits in memory, corpus has: 765 sentence pairs.
 Train total # sentence pairs (weighted): 765
Size of source portion of the training corpus: 15791 tokens
Size of the target portion of the training corpus: 15245 tokens 
In source portion of the training corpus, only 2586 unique tokens appeared
In target portion of the training corpus, only 2707 unique tokens appeared
lambda for PP calculation in IBM-1,IBM-2,HMM:= 15245/(16556-765)== 0.965423
There are 153528 153528 entries in table
==========================================================
Model1 Training Started at: Thu Apr 14 13:34:22 2016

-----------
Model1: Iteration 1
Model1: (1) TRAIN CROSS-ENTROPY 11.599 PERPLEXITY 3102.14
Model1: (1) VITERBI TRAIN CROSS-ENTROPY 16.2664 PERPLEXITY 78825.9
Model 1 Iteration: 1 took: 0 seconds
-----------
Model1: Iteration 2
Model1: (2) TRAIN CROSS-ENTROPY 6.13123 PERPLEXITY 70.0947
Model1: (2) VITERBI TRAIN CROSS-ENTROPY 9.09065 PERPLEXITY 545.205
Model 1 Iteration: 2 took: 0 seconds
-----------
Model1: Iteration 3
Model1: (3) TRAIN CROSS-ENTROPY 5.68009 PERPLEXITY 51.2717
Model1: (3) VITERBI TRAIN CROSS-ENTROPY 8.19306 PERPLEXITY 292.656
Model 1 Iteration: 3 took: 0 seconds
-----------
Model1: Iteration 4
Model1: (4) TRAIN CROSS-ENTROPY 5.455 PERPLEXITY 43.8651
Model1: (4) VITERBI TRAIN CROSS-ENTROPY 7.57357 PERPLEXITY 190.49
Model 1 Iteration: 4 took: 0 seconds
-----------
Model1: Iteration 5
Model1: (5) TRAIN CROSS-ENTROPY 5.33269 PERPLEXITY 40.2995
Model1: (5) VITERBI TRAIN CROSS-ENTROPY 7.19215 PERPLEXITY 146.235
Model 1 Iteration: 5 took: 0 seconds
Entire Model1 Training took: 0 seconds
NOTE: I am doing iterations with the HMM model!
Read classes: #words: 2586  #classes: 51
Read classes: #words: 2708  #classes: 51

==========================================================
Hmm Training Started at: Thu Apr 14 13:34:22 2016

-----------
Hmm: Iteration 1
A/D table contains 48760 parameters.
Hmm: (1) TRAIN CROSS-ENTROPY 5.26225 PERPLEXITY 38.3792
Hmm: (1) VITERBI TRAIN CROSS-ENTROPY 6.94923 PERPLEXITY 123.574

Hmm Iteration: 1 took: 1 seconds

-----------
Hmm: Iteration 2
A/D table contains 48760 parameters.
Hmm: (2) TRAIN CROSS-ENTROPY 4.97572 PERPLEXITY 31.4659
Hmm: (2) VITERBI TRAIN CROSS-ENTROPY 5.77219 PERPLEXITY 54.6515

Hmm Iteration: 2 took: 0 seconds

-----------
Hmm: Iteration 3
A/D table contains 48760 parameters.
Hmm: (3) TRAIN CROSS-ENTROPY 4.21203 PERPLEXITY 18.5331
Hmm: (3) VITERBI TRAIN CROSS-ENTROPY 4.59523 PERPLEXITY 24.1714

Hmm Iteration: 3 took: 1 seconds

-----------
Hmm: Iteration 4
A/D table contains 48760 parameters.
Hmm: (4) TRAIN CROSS-ENTROPY 3.59012 PERPLEXITY 12.043
Hmm: (4) VITERBI TRAIN CROSS-ENTROPY 3.80244 PERPLEXITY 13.9524

Hmm Iteration: 4 took: 0 seconds

-----------
Hmm: Iteration 5
A/D table contains 48760 parameters.
Hmm: (5) TRAIN CROSS-ENTROPY 3.28541 PERPLEXITY 9.75005
Hmm: (5) VITERBI TRAIN CROSS-ENTROPY 3.42927 PERPLEXITY 10.7725

Hmm Iteration: 5 took: 1 seconds

Entire Hmm Training took: 3 seconds
==========================================================
Read classes: #words: 2586  #classes: 51
Read classes: #words: 2708  #classes: 51
Read classes: #words: 2586  #classes: 51
Read classes: #words: 2708  #classes: 51

==========================================================
Starting H333444:  Viterbi Training
 H333444 Training Started at: Thu Apr 14 13:34:25 2016


---------------------
THTo3: Iteration 1
#centers(pre/hillclimbed/real): 1 1 1  #al: 798.565 #alsophisticatedcountcollection: 0 #hcsteps: 0
#peggingImprovements: 0
A/D table contains 48760 parameters.
A/D table contains 49879 parameters.
NTable contains 25870 parameter.
p0_count is 13117.7 and p1 is 1063.64; p0 is 0.999 p1: 0.001
THTo3: TRAIN CROSS-ENTROPY 3.00804 PERPLEXITY 8.0447
THTo3: (1) TRAIN VITERBI CROSS-ENTROPY 3.06962 PERPLEXITY 8.39555

THTo3 Viterbi Iteration : 1 took: 1 seconds

---------------------
Model3: Iteration 2
#centers(pre/hillclimbed/real): 1 1 1  #al: 799.265 #alsophisticatedcountcollection: 0 #hcsteps: 2.00784
#peggingImprovements: 0
A/D table contains 48760 parameters.
A/D table contains 49876 parameters.
NTable contains 25870 parameter.
p0_count is 13749.5 and p1 is 747.764; p0 is 0.999 p1: 0.001
Model3: TRAIN CROSS-ENTROPY 4.0817 PERPLEXITY 16.9322
Model3: (2) TRAIN VITERBI CROSS-ENTROPY 4.13088 PERPLEXITY 17.5194

Model3 Viterbi Iteration : 2 took: 0 seconds

---------------------
Model3: Iteration 3
#centers(pre/hillclimbed/real): 1 1 1  #al: 799.488 #alsophisticatedcountcollection: 0 #hcsteps: 2.12549
#peggingImprovements: 0
A/D table contains 48760 parameters.
A/D table contains 49876 parameters.
NTable contains 25870 parameter.
p0_count is 13997.2 and p1 is 623.915; p0 is 0.999 p1: 0.001
Model3: TRAIN CROSS-ENTROPY 3.92086 PERPLEXITY 15.146
Model3: (3) TRAIN VITERBI CROSS-ENTROPY 3.96042 PERPLEXITY 15.567

Model3 Viterbi Iteration : 3 took: 0 seconds

---------------------
T3To4: Iteration 4
#centers(pre/hillclimbed/real): 1 1 1  #al: 799.567 #alsophisticatedcountcollection: 16.8771 #hcsteps: 2.22484
#peggingImprovements: 0
D4 table contains 448427 parameters.
A/D table contains 48760 parameters.
A/D table contains 49793 parameters.
NTable contains 25870 parameter.
p0_count is 14175.3 and p1 is 534.859; p0 is 0.999 p1: 0.001
T3To4: TRAIN CROSS-ENTROPY 3.84922 PERPLEXITY 14.4122
T3To4: (4) TRAIN VITERBI CROSS-ENTROPY 3.88425 PERPLEXITY 14.7665

T3To4 Viterbi Iteration : 4 took: 1 seconds

---------------------
Model4: Iteration 5
#centers(pre/hillclimbed/real): 1 1 1  #al: 799.599 #alsophisticatedcountcollection: 15.8471 #hcsteps: 1.91242
#peggingImprovements: 0
D4 table contains 448427 parameters.
A/D table contains 48760 parameters.
A/D table contains 49787 parameters.
NTable contains 25870 parameter.
p0_count is 14175.2 and p1 is 534.917; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 3.56679 PERPLEXITY 11.8498
Model4: (5) TRAIN VITERBI CROSS-ENTROPY 3.5932 PERPLEXITY 12.0687

Model4 Viterbi Iteration : 5 took: 0 seconds

---------------------
Model4: Iteration 6
#centers(pre/hillclimbed/real): 1 1 1  #al: 799.637 #alsophisticatedcountcollection: 12.5529 #hcsteps: 1.86797
#peggingImprovements: 0
D4 table contains 448630 parameters.
A/D table contains 48760 parameters.
A/D table contains 49862 parameters.
NTable contains 25870 parameter.
p0_count is 14209.7 and p1 is 517.665; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 3.46151 PERPLEXITY 11.0158
Model4: (6) TRAIN VITERBI CROSS-ENTROPY 3.48333 PERPLEXITY 11.1837

Model4 Viterbi Iteration : 6 took: 1 seconds
H333444 Training Finished at: Thu Apr 14 13:34:28 2016


Entire Viterbi H333444 Training took: 3 seconds
==========================================================

Entire Training took: 6 seconds
Program Finished at: Thu Apr 14 13:34:28 2016

==========================================================
Executing: rm -f /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en.A3.final.gz
Executing: gzip /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en.A3.final
(2.1a) running snt2cooc en-fr @ Thu Apr 14 13:34:28 IST 2016

Executing: mkdir -p /users/case4/smitha47/SMT-Project/working/train/giza.en-fr
Executing: /usr/local/mosesdecoder/tools/snt2cooc.out /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb /users/case4/smitha47/SMT-Project/working/train/corpus/en-fr-int-train.snt > /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr.cooc
/usr/local/mosesdecoder/tools/snt2cooc.out /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb /users/case4/smitha47/SMT-Project/working/train/corpus/en-fr-int-train.snt > /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr.cooc
END.
(2.1b) running giza en-fr @ Thu Apr 14 13:34:29 IST 2016
/usr/local/mosesdecoder/tools/GIZA++  -CoocurrenceFile /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr.cooc -c /users/case4/smitha47/SMT-Project/working/train/corpus/en-fr-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr -onlyaldumps 1 -p0 0.999 -s /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb -t /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb
Executing: /usr/local/mosesdecoder/tools/GIZA++  -CoocurrenceFile /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr.cooc -c /users/case4/smitha47/SMT-Project/working/train/corpus/en-fr-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr -onlyaldumps 1 -p0 0.999 -s /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb -t /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb
/usr/local/mosesdecoder/tools/GIZA++  -CoocurrenceFile /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr.cooc -c /users/case4/smitha47/SMT-Project/working/train/corpus/en-fr-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr -onlyaldumps 1 -p0 0.999 -s /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb -t /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb
Parameter 'coocurrencefile' changed from '' to '/users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr.cooc'
Parameter 'c' changed from '' to '/users/case4/smitha47/SMT-Project/working/train/corpus/en-fr-int-train.snt'
Parameter 'm3' changed from '5' to '3'
Parameter 'm4' changed from '5' to '3'
Parameter 'model1dumpfrequency' changed from '0' to '1'
Parameter 'model4smoothfactor' changed from '0.2' to '0.4'
Parameter 'nodumps' changed from '0' to '1'
Parameter 'nsmooth' changed from '64' to '4'
Parameter 'o' changed from '116-04-14.133429.smitha47' to '/users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr'
Parameter 'onlyaldumps' changed from '0' to '1'
Parameter 'p0' changed from '-1' to '0.999'
Parameter 's' changed from '' to '/users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb'
Parameter 't' changed from '' to '/users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb'
general parameters:
-------------------
ml = 101  (maximum sentence length)

No. of iterations:
-------------------
hmmiterations = 5  (mh)
model1iterations = 5  (number of iterations for Model 1)
model2iterations = 0  (number of iterations for Model 2)
model3iterations = 3  (number of iterations for Model 3)
model4iterations = 3  (number of iterations for Model 4)
model5iterations = 0  (number of iterations for Model 5)
model6iterations = 0  (number of iterations for Model 6)

parameter for various heuristics in GIZA++ for efficient training:
------------------------------------------------------------------
countincreasecutoff = 1e-06  (Counts increment cutoff threshold)
countincreasecutoffal = 1e-05  (Counts increment cutoff threshold for alignments in training of fertility models)
mincountincrease = 1e-07  (minimal count increase)
peggedcutoff = 0.03  (relative cutoff probability for alignment-centers in pegging)
probcutoff = 1e-07  (Probability cutoff threshold for lexicon probabilities)
probsmooth = 1e-07  (probability smoothing (floor) value )

parameters for describing the type and amount of output:
-----------------------------------------------------------
compactalignmentformat = 0  (0: detailled alignment format, 1: compact alignment format )
hmmdumpfrequency = 0  (dump frequency of HMM)
l = 116-04-14.133429.smitha47.log  (log file name)
log = 0  (0: no logfile; 1: logfile)
model1dumpfrequency = 1  (dump frequency of Model 1)
model2dumpfrequency = 0  (dump frequency of Model 2)
model345dumpfrequency = 0  (dump frequency of Model 3/4/5)
nbestalignments = 0  (for printing the n best alignments)
nodumps = 1  (1: do not write any files)
o = /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr  (output file prefix)
onlyaldumps = 1  (1: do not write any files)
outputpath =   (output path)
transferdumpfrequency = 0  (output: dump of transfer from Model 2 to 3)
verbose = 0  (0: not verbose; 1: verbose)
verbosesentence = -10  (number of sentence for which a lot of information should be printed (negative: no output))

parameters describing input files:
----------------------------------
c = /users/case4/smitha47/SMT-Project/working/train/corpus/en-fr-int-train.snt  (training corpus file name)
d =   (dictionary file name)
s = /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb  (source vocabulary file name)
t = /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb  (target vocabulary file name)
tc =   (test corpus file name)

smoothing parameters:
---------------------
emalsmooth = 0.2  (f-b-trn: smoothing factor for HMM alignment model (can be ignored by -emSmoothHMM))
model23smoothfactor = 0  (smoothing parameter for IBM-2/3 (interpolation with constant))
model4smoothfactor = 0.4  (smooting parameter for alignment probabilities in Model 4)
model5smoothfactor = 0.1  (smooting parameter for distortion probabilities in Model 5 (linear interpolation with constant))
nsmooth = 4  (smoothing for fertility parameters (good value: 64): weight for wordlength-dependent fertility parameters)
nsmoothgeneral = 0  (smoothing for fertility parameters (default: 0): weight for word-independent fertility parameters)

parameters modifying the models:
--------------------------------
compactadtable = 1  (1: only 3-dimensional alignment table for IBM-2 and IBM-3)
deficientdistortionforemptyword = 0  (0: IBM-3/IBM-4 as described in (Brown et al. 1993); 1: distortion model of empty word is deficient; 2: distoriton model of empty word is deficient (differently); setting this parameter also helps to avoid that during IBM-3 and IBM-4 training too many words are aligned with the empty word)
depm4 = 76  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
depm5 = 68  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
emalignmentdependencies = 2  (lextrain: dependencies in the HMM alignment model.  &1: sentence length; &2: previous class; &4: previous position;  &8: French position; &16: French class)
emprobforempty = 0.4  (f-b-trn: probability for empty word)

parameters modifying the EM-algorithm:
--------------------------------------
m5p0 = -1  (fixed value for parameter p_0 in IBM-5 (if negative then it is determined in training))
manlexfactor1 = 0  ()
manlexfactor2 = 0  ()
manlexmaxmultiplicity = 20  ()
maxfertility = 10  (maximal fertility for fertility models)
p0 = 0.999  (fixed value for parameter p_0 in IBM-3/4 (if negative then it is determined in training))
pegging = 0  (0: no pegging; 1: do pegging)

general parameters:
-------------------
ml = 101  (maximum sentence length)

No. of iterations:
-------------------
hmmiterations = 5  (mh)
model1iterations = 5  (number of iterations for Model 1)
model2iterations = 0  (number of iterations for Model 2)
model3iterations = 3  (number of iterations for Model 3)
model4iterations = 3  (number of iterations for Model 4)
model5iterations = 0  (number of iterations for Model 5)
model6iterations = 0  (number of iterations for Model 6)

parameter for various heuristics in GIZA++ for efficient training:
------------------------------------------------------------------
countincreasecutoff = 1e-06  (Counts increment cutoff threshold)
countincreasecutoffal = 1e-05  (Counts increment cutoff threshold for alignments in training of fertility models)
mincountincrease = 1e-07  (minimal count increase)
peggedcutoff = 0.03  (relative cutoff probability for alignment-centers in pegging)
probcutoff = 1e-07  (Probability cutoff threshold for lexicon probabilities)
probsmooth = 1e-07  (probability smoothing (floor) value )

parameters for describing the type and amount of output:
-----------------------------------------------------------
compactalignmentformat = 0  (0: detailled alignment format, 1: compact alignment format )
hmmdumpfrequency = 0  (dump frequency of HMM)
l = 116-04-14.133429.smitha47.log  (log file name)
log = 0  (0: no logfile; 1: logfile)
model1dumpfrequency = 1  (dump frequency of Model 1)
model2dumpfrequency = 0  (dump frequency of Model 2)
model345dumpfrequency = 0  (dump frequency of Model 3/4/5)
nbestalignments = 0  (for printing the n best alignments)
nodumps = 1  (1: do not write any files)
o = /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr  (output file prefix)
onlyaldumps = 1  (1: do not write any files)
outputpath =   (output path)
transferdumpfrequency = 0  (output: dump of transfer from Model 2 to 3)
verbose = 0  (0: not verbose; 1: verbose)
verbosesentence = -10  (number of sentence for which a lot of information should be printed (negative: no output))

parameters describing input files:
----------------------------------
c = /users/case4/smitha47/SMT-Project/working/train/corpus/en-fr-int-train.snt  (training corpus file name)
d =   (dictionary file name)
s = /users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb  (source vocabulary file name)
t = /users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb  (target vocabulary file name)
tc =   (test corpus file name)

smoothing parameters:
---------------------
emalsmooth = 0.2  (f-b-trn: smoothing factor for HMM alignment model (can be ignored by -emSmoothHMM))
model23smoothfactor = 0  (smoothing parameter for IBM-2/3 (interpolation with constant))
model4smoothfactor = 0.4  (smooting parameter for alignment probabilities in Model 4)
model5smoothfactor = 0.1  (smooting parameter for distortion probabilities in Model 5 (linear interpolation with constant))
nsmooth = 4  (smoothing for fertility parameters (good value: 64): weight for wordlength-dependent fertility parameters)
nsmoothgeneral = 0  (smoothing for fertility parameters (default: 0): weight for word-independent fertility parameters)

parameters modifying the models:
--------------------------------
compactadtable = 1  (1: only 3-dimensional alignment table for IBM-2 and IBM-3)
deficientdistortionforemptyword = 0  (0: IBM-3/IBM-4 as described in (Brown et al. 1993); 1: distortion model of empty word is deficient; 2: distoriton model of empty word is deficient (differently); setting this parameter also helps to avoid that during IBM-3 and IBM-4 training too many words are aligned with the empty word)
depm4 = 76  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
depm5 = 68  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
emalignmentdependencies = 2  (lextrain: dependencies in the HMM alignment model.  &1: sentence length; &2: previous class; &4: previous position;  &8: French position; &16: French class)
emprobforempty = 0.4  (f-b-trn: probability for empty word)

parameters modifying the EM-algorithm:
--------------------------------------
m5p0 = -1  (fixed value for parameter p_0 in IBM-5 (if negative then it is determined in training))
manlexfactor1 = 0  ()
manlexfactor2 = 0  ()
manlexmaxmultiplicity = 20  ()
maxfertility = 10  (maximal fertility for fertility models)
p0 = 0.999  (fixed value for parameter p_0 in IBM-3/4 (if negative then it is determined in training))
pegging = 0  (0: no pegging; 1: do pegging)

reading vocabulary files 
Reading vocabulary file from:/users/case4/smitha47/SMT-Project/working/train/corpus/fr.vcb
Reading vocabulary file from:/users/case4/smitha47/SMT-Project/working/train/corpus/en.vcb
Source vocabulary list has 2709 unique tokens 
Target vocabulary list has 2587 unique tokens 
Calculating vocabulary frequencies from corpus /users/case4/smitha47/SMT-Project/working/train/corpus/en-fr-int-train.snt
Reading more sentence pairs into memory ... 
Corpus fits in memory, corpus has: 765 sentence pairs.
 Train total # sentence pairs (weighted): 765
Size of source portion of the training corpus: 15245 tokens
Size of the target portion of the training corpus: 15791 tokens 
In source portion of the training corpus, only 2708 unique tokens appeared
In target portion of the training corpus, only 2585 unique tokens appeared
lambda for PP calculation in IBM-1,IBM-2,HMM:= 15791/(16010-765)== 1.03582
There are 153406 153406 entries in table
==========================================================
Model1 Training Started at: Thu Apr 14 13:34:29 2016

-----------
Model1: Iteration 1
Model1: (1) TRAIN CROSS-ENTROPY 11.5195 PERPLEXITY 2935.71
Model1: (1) VITERBI TRAIN CROSS-ENTROPY 16.1226 PERPLEXITY 71350.1
Model 1 Iteration: 1 took: 0 seconds
-----------
Model1: Iteration 2
Model1: (2) TRAIN CROSS-ENTROPY 5.87716 PERPLEXITY 58.7762
Model1: (2) VITERBI TRAIN CROSS-ENTROPY 8.84415 PERPLEXITY 459.574
Model 1 Iteration: 2 took: 0 seconds
-----------
Model1: Iteration 3
Model1: (3) TRAIN CROSS-ENTROPY 5.41567 PERPLEXITY 42.6854
Model1: (3) VITERBI TRAIN CROSS-ENTROPY 7.8568 PERPLEXITY 231.811
Model 1 Iteration: 3 took: 0 seconds
-----------
Model1: Iteration 4
Model1: (4) TRAIN CROSS-ENTROPY 5.18488 PERPLEXITY 36.3751
Model1: (4) VITERBI TRAIN CROSS-ENTROPY 7.21084 PERPLEXITY 148.142
Model 1 Iteration: 4 took: 0 seconds
-----------
Model1: Iteration 5
Model1: (5) TRAIN CROSS-ENTROPY 5.06046 PERPLEXITY 33.3696
Model1: (5) VITERBI TRAIN CROSS-ENTROPY 6.82725 PERPLEXITY 113.556
Model 1 Iteration: 5 took: 0 seconds
Entire Model1 Training took: 0 seconds
NOTE: I am doing iterations with the HMM model!
Read classes: #words: 2708  #classes: 51
Read classes: #words: 2586  #classes: 51

==========================================================
Hmm Training Started at: Thu Apr 14 13:34:29 2016

-----------
Hmm: Iteration 1
A/D table contains 50280 parameters.
Hmm: (1) TRAIN CROSS-ENTROPY 4.98986 PERPLEXITY 31.7758
Hmm: (1) VITERBI TRAIN CROSS-ENTROPY 6.59053 PERPLEXITY 96.371

Hmm Iteration: 1 took: 0 seconds

-----------
Hmm: Iteration 2
A/D table contains 50280 parameters.
Hmm: (2) TRAIN CROSS-ENTROPY 4.67797 PERPLEXITY 25.5981
Hmm: (2) VITERBI TRAIN CROSS-ENTROPY 5.42362 PERPLEXITY 42.9211

Hmm Iteration: 2 took: 1 seconds

-----------
Hmm: Iteration 3
A/D table contains 50280 parameters.
Hmm: (3) TRAIN CROSS-ENTROPY 3.8966 PERPLEXITY 14.8934
Hmm: (3) VITERBI TRAIN CROSS-ENTROPY 4.23918 PERPLEXITY 18.8851

Hmm Iteration: 3 took: 0 seconds

-----------
Hmm: Iteration 4
A/D table contains 50280 parameters.
Hmm: (4) TRAIN CROSS-ENTROPY 3.28375 PERPLEXITY 9.73884
Hmm: (4) VITERBI TRAIN CROSS-ENTROPY 3.47148 PERPLEXITY 11.0922

Hmm Iteration: 4 took: 1 seconds

-----------
Hmm: Iteration 5
A/D table contains 50280 parameters.
Hmm: (5) TRAIN CROSS-ENTROPY 3.0066 PERPLEXITY 8.03669
Hmm: (5) VITERBI TRAIN CROSS-ENTROPY 3.14051 PERPLEXITY 8.81834

Hmm Iteration: 5 took: 0 seconds

Entire Hmm Training took: 2 seconds
==========================================================
Read classes: #words: 2708  #classes: 51
Read classes: #words: 2586  #classes: 51
Read classes: #words: 2708  #classes: 51
Read classes: #words: 2586  #classes: 51

==========================================================
Starting H333444:  Viterbi Training
 H333444 Training Started at: Thu Apr 14 13:34:31 2016


---------------------
THTo3: Iteration 1
#centers(pre/hillclimbed/real): 1 1 1  #al: 810.911 #alsophisticatedcountcollection: 0 #hcsteps: 0
#peggingImprovements: 0
A/D table contains 50280 parameters.
A/D table contains 48443 parameters.
NTable contains 27090 parameter.
p0_count is 14007.9 and p1 is 891.539; p0 is 0.999 p1: 0.001
THTo3: TRAIN CROSS-ENTROPY 2.75865 PERPLEXITY 6.76762
THTo3: (1) TRAIN VITERBI CROSS-ENTROPY 2.81998 PERPLEXITY 7.06155

THTo3 Viterbi Iteration : 1 took: 1 seconds

---------------------
Model3: Iteration 2
#centers(pre/hillclimbed/real): 1 1 1  #al: 811.37 #alsophisticatedcountcollection: 0 #hcsteps: 2.17908
#peggingImprovements: 0
A/D table contains 50280 parameters.
A/D table contains 48443 parameters.
NTable contains 27090 parameter.
p0_count is 14850.8 and p1 is 470.087; p0 is 0.999 p1: 0.001
Model3: TRAIN CROSS-ENTROPY 3.78395 PERPLEXITY 13.7747
Model3: (2) TRAIN VITERBI CROSS-ENTROPY 3.8333 PERPLEXITY 14.2541

Model3 Viterbi Iteration : 2 took: 0 seconds

---------------------
Model3: Iteration 3
#centers(pre/hillclimbed/real): 1 1 1  #al: 811.482 #alsophisticatedcountcollection: 0 #hcsteps: 2.30196
#peggingImprovements: 0
A/D table contains 50280 parameters.
A/D table contains 48443 parameters.
NTable contains 27090 parameter.
p0_count is 15023.5 and p1 is 383.767; p0 is 0.999 p1: 0.001
Model3: TRAIN CROSS-ENTROPY 3.64558 PERPLEXITY 12.5149
Model3: (3) TRAIN VITERBI CROSS-ENTROPY 3.68371 PERPLEXITY 12.8501

Model3 Viterbi Iteration : 3 took: 1 seconds

---------------------
T3To4: Iteration 4
#centers(pre/hillclimbed/real): 1 1 1  #al: 811.573 #alsophisticatedcountcollection: 19.3712 #hcsteps: 2.33333
#peggingImprovements: 0
D4 table contains 448833 parameters.
A/D table contains 50280 parameters.
A/D table contains 48397 parameters.
NTable contains 27090 parameter.
p0_count is 15100 and p1 is 345.522; p0 is 0.999 p1: 0.001
T3To4: TRAIN CROSS-ENTROPY 3.58966 PERPLEXITY 12.0391
T3To4: (4) TRAIN VITERBI CROSS-ENTROPY 3.62281 PERPLEXITY 12.319

T3To4 Viterbi Iteration : 4 took: 0 seconds

---------------------
Model4: Iteration 5
#centers(pre/hillclimbed/real): 1 1 1  #al: 811.55 #alsophisticatedcountcollection: 18.0196 #hcsteps: 2.1098
#peggingImprovements: 0
D4 table contains 448833 parameters.
A/D table contains 50280 parameters.
A/D table contains 48305 parameters.
NTable contains 27090 parameter.
p0_count is 15026.3 and p1 is 382.331; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 3.19107 PERPLEXITY 9.1329
Model4: (5) TRAIN VITERBI CROSS-ENTROPY 3.21468 PERPLEXITY 9.28359

Model4 Viterbi Iteration : 5 took: 1 seconds

---------------------
Model4: Iteration 6
#centers(pre/hillclimbed/real): 1 1 1  #al: 811.569 #alsophisticatedcountcollection: 14.6288 #hcsteps: 2.10065
#peggingImprovements: 0
D4 table contains 448833 parameters.
A/D table contains 50280 parameters.
A/D table contains 48275 parameters.
NTable contains 27090 parameter.
p0_count is 15055.5 and p1 is 367.772; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 3.08149 PERPLEXITY 8.46485
Model4: (6) TRAIN VITERBI CROSS-ENTROPY 3.10071 PERPLEXITY 8.57839

Model4 Viterbi Iteration : 6 took: 1 seconds
H333444 Training Finished at: Thu Apr 14 13:34:35 2016


Entire Viterbi H333444 Training took: 4 seconds
==========================================================

Entire Training took: 6 seconds
Program Finished at: Thu Apr 14 13:34:35 2016

==========================================================
Executing: rm -f /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr.A3.final.gz
Executing: gzip /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr.A3.final
(3) generate word alignment @ Thu Apr 14 13:34:35 IST 2016
Combining forward and inverted alignment from files:
  /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en.A3.final.{bz2,gz}
  /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr.A3.final.{bz2,gz}
Executing: mkdir -p /users/case4/smitha47/SMT-Project/working/train/model
Executing: /usr/local/mosesdecoder/scripts/training/giza2bal.pl -d "gzip -cd /users/case4/smitha47/SMT-Project/working/train/giza.en-fr/en-fr.A3.final.gz" -i "gzip -cd /users/case4/smitha47/SMT-Project/working/train/giza.fr-en/fr-en.A3.final.gz" |/usr/local/mosesdecoder/scripts/../bin/symal -alignment="grow" -diagonal="yes" -final="yes" -both="yes" > /users/case4/smitha47/SMT-Project/working/train/model/aligned.grow-diag-final-and
symal: computing grow alignment: diagonal (1) final (1)both-uncovered (1)
skip=<0> counts=<765>
(4) generate lexical translation table 0-0 @ Thu Apr 14 13:34:35 IST 2016
(/users/case4/smitha47/SMT-Project/corpus/train-data-clean.fr,/users/case4/smitha47/SMT-Project/corpus/train-data-clean.en,/users/case4/smitha47/SMT-Project/working/train/model/lex)
!
Saved: /users/case4/smitha47/SMT-Project/working/train/model/lex.f2e and /users/case4/smitha47/SMT-Project/working/train/model/lex.e2f
FILE: /users/case4/smitha47/SMT-Project/corpus/train-data-clean.en
FILE: /users/case4/smitha47/SMT-Project/corpus/train-data-clean.fr
FILE: /users/case4/smitha47/SMT-Project/working/train/model/aligned.grow-diag-final-and
(5) extract phrases @ Thu Apr 14 13:34:35 IST 2016
/usr/local/mosesdecoder/scripts/generic/extract-parallel.perl 1 split "sort    " /usr/local/mosesdecoder/scripts/../bin/extract /users/case4/smitha47/SMT-Project/corpus/train-data-clean.en /users/case4/smitha47/SMT-Project/corpus/train-data-clean.fr /users/case4/smitha47/SMT-Project/working/train/model/aligned.grow-diag-final-and /users/case4/smitha47/SMT-Project/working/train/model/extract 7 orientation --model wbe-msd --GZOutput 
Executing: /usr/local/mosesdecoder/scripts/generic/extract-parallel.perl 1 split "sort    " /usr/local/mosesdecoder/scripts/../bin/extract /users/case4/smitha47/SMT-Project/corpus/train-data-clean.en /users/case4/smitha47/SMT-Project/corpus/train-data-clean.fr /users/case4/smitha47/SMT-Project/working/train/model/aligned.grow-diag-final-and /users/case4/smitha47/SMT-Project/working/train/model/extract 7 orientation --model wbe-msd --GZOutput 
MAX 7 1 0
Started Thu Apr 14 13:34:35 2016
Executing: ln -s /users/case4/smitha47/SMT-Project/corpus/train-data-clean.en /users/case4/smitha47/SMT-Project/working/train/model/tmp.5976/target.00000 
total=765 line-per-split=766 
Executing: ln -s /users/case4/smitha47/SMT-Project/corpus/train-data-clean.fr /users/case4/smitha47/SMT-Project/working/train/model/tmp.5976/source.00000 
Executing: ln -s /users/case4/smitha47/SMT-Project/working/train/model/aligned.grow-diag-final-and /users/case4/smitha47/SMT-Project/working/train/model/tmp.5976/align.00000 
/usr/local/mosesdecoder/scripts/../bin/extract /users/case4/smitha47/SMT-Project/working/train/model/tmp.5976/target.00000 /users/case4/smitha47/SMT-Project/working/train/model/tmp.5976/source.00000 /users/case4/smitha47/SMT-Project/working/train/model/tmp.5976/align.00000 /users/case4/smitha47/SMT-Project/working/train/model/tmp.5976/extract.00000  7 orientation --model wbe-msd --GZOutput   --SentenceOffset 0 2>> /dev/stderr 
glueArg= 
merging extract / extract.inv
gunzip -c /users/case4/smitha47/SMT-Project/working/train/model/tmp.5976/extract.00000.o.gz  | LC_ALL=C sort     -T /users/case4/smitha47/SMT-Project/working/train/model/tmp.5976 2>> /dev/stderr | gzip -c > /users/case4/smitha47/SMT-Project/working/train/model/extract.o.sorted.gz 2>> /dev/stderr 
rm -rf /users/case4/smitha47/SMT-Project/working/train/model/tmp.5976 
Finished Thu Apr 14 13:34:37 2016
(6) score phrases @ Thu Apr 14 13:34:37 IST 2016
(6.1)  creating table half /users/case4/smitha47/SMT-Project/working/train/model/phrase-table.half.f2e @ Thu Apr 14 13:34:37 IST 2016
/usr/local/mosesdecoder/scripts/generic/score-parallel.perl 1 "sort    " /usr/local/mosesdecoder/scripts/../bin/score /users/case4/smitha47/SMT-Project/working/train/model/extract.sorted.gz /users/case4/smitha47/SMT-Project/working/train/model/lex.f2e /users/case4/smitha47/SMT-Project/working/train/model/phrase-table.half.f2e.gz  0 
Executing: /usr/local/mosesdecoder/scripts/generic/score-parallel.perl 1 "sort    " /usr/local/mosesdecoder/scripts/../bin/score /users/case4/smitha47/SMT-Project/working/train/model/extract.sorted.gz /users/case4/smitha47/SMT-Project/working/train/model/lex.f2e /users/case4/smitha47/SMT-Project/working/train/model/phrase-table.half.f2e.gz  0 
Started Thu Apr 14 13:34:37 2016
ln -s /users/case4/smitha47/SMT-Project/working/train/model/extract.sorted.gz /users/case4/smitha47/SMT-Project/working/train/model/tmp.6006/extract.0.gz 
/usr/local/mosesdecoder/scripts/../bin/score /users/case4/smitha47/SMT-Project/working/train/model/tmp.6006/extract.0.gz /users/case4/smitha47/SMT-Project/working/train/model/lex.f2e /users/case4/smitha47/SMT-Project/working/train/model/tmp.6006/phrase-table.half.00000.gz  2>> /dev/stderr 
/users/case4/smitha47/SMT-Project/working/train/model/tmp.6006/run.0.shmv /users/case4/smitha47/SMT-Project/working/train/model/tmp.6006/phrase-table.half.00000.gz /users/case4/smitha47/SMT-Project/working/train/model/phrase-table.half.f2e.gzrm -rf /users/case4/smitha47/SMT-Project/working/train/model/tmp.6006 
Finished Thu Apr 14 13:34:39 2016
(6.3)  creating table half /users/case4/smitha47/SMT-Project/working/train/model/phrase-table.half.e2f @ Thu Apr 14 13:34:39 IST 2016
/usr/local/mosesdecoder/scripts/generic/score-parallel.perl 1 "sort    " /usr/local/mosesdecoder/scripts/../bin/score /users/case4/smitha47/SMT-Project/working/train/model/extract.inv.sorted.gz /users/case4/smitha47/SMT-Project/working/train/model/lex.e2f /users/case4/smitha47/SMT-Project/working/train/model/phrase-table.half.e2f.gz --Inverse 1 
Executing: /usr/local/mosesdecoder/scripts/generic/score-parallel.perl 1 "sort    " /usr/local/mosesdecoder/scripts/../bin/score /users/case4/smitha47/SMT-Project/working/train/model/extract.inv.sorted.gz /users/case4/smitha47/SMT-Project/working/train/model/lex.e2f /users/case4/smitha47/SMT-Project/working/train/model/phrase-table.half.e2f.gz --Inverse 1 
Started Thu Apr 14 13:34:39 2016
ln -s /users/case4/smitha47/SMT-Project/working/train/model/extract.inv.sorted.gz /users/case4/smitha47/SMT-Project/working/train/model/tmp.6016/extract.0.gz 
/usr/local/mosesdecoder/scripts/../bin/score /users/case4/smitha47/SMT-Project/working/train/model/tmp.6016/extract.0.gz /users/case4/smitha47/SMT-Project/working/train/model/lex.e2f /users/case4/smitha47/SMT-Project/working/train/model/tmp.6016/phrase-table.half.00000.gz --Inverse  2>> /dev/stderr 
/users/case4/smitha47/SMT-Project/working/train/model/tmp.6016/run.0.shgunzip -c /users/case4/smitha47/SMT-Project/working/train/model/tmp.6016/phrase-table.half.*.gz 2>> /dev/stderr| LC_ALL=C sort     -T /users/case4/smitha47/SMT-Project/working/train/model/tmp.6016  | gzip -c > /users/case4/smitha47/SMT-Project/working/train/model/phrase-table.half.e2f.gz  2>> /dev/stderr rm -rf /users/case4/smitha47/SMT-Project/working/train/model/tmp.6016 
Finished Thu Apr 14 13:34:40 2016
(6.6) consolidating the two halves @ Thu Apr 14 13:34:40 IST 2016
Executing: /usr/local/mosesdecoder/scripts/../bin/consolidate /users/case4/smitha47/SMT-Project/working/train/model/phrase-table.half.f2e.gz /users/case4/smitha47/SMT-Project/working/train/model/phrase-table.half.e2f.gz /dev/stdout | gzip -c > /users/case4/smitha47/SMT-Project/working/train/model/phrase-table.gz
Consolidate v2.0 written by Philipp Koehn
consolidating direct and indirect rule tables
Executing: rm -f /users/case4/smitha47/SMT-Project/working/train/model/phrase-table.half.*
(7) learn reordering model @ Thu Apr 14 13:34:41 IST 2016
(7.1) [no factors] learn reordering model @ Thu Apr 14 13:34:41 IST 2016
(7.2) building tables @ Thu Apr 14 13:34:41 IST 2016
Executing: /usr/local/mosesdecoder/scripts/../bin/lexical-reordering-score /users/case4/smitha47/SMT-Project/working/train/model/extract.o.sorted.gz 0.5 /users/case4/smitha47/SMT-Project/working/train/model/reordering-table. --model "wbe msd wbe-msd-bidirectional-fe"
Lexical Reordering Scorer
scores lexical reordering models of several types (hierarchical, phrase-based and word-based-extraction
(8) learn generation model @ Thu Apr 14 13:34:42 IST 2016
  no generation model requested, skipping step
(9) create moses.ini @ Thu Apr 14 13:34:42 IST 2016
